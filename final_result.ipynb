{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from utils import choose_best_threshold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils import SOTA, XFORMER, OLD, MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data where\n",
    "# 1. duplication has been removed.\n",
    "# 2. examples that annotated in different datasets with different factual consistency labels are manually corrected based on our judgment.\n",
    "df = pd.read_csv(\"data/aggre_fact_final.csv\")\n",
    "\n",
    "# split data\n",
    "df_val = df[df.cut == 'val']\n",
    "df_val_sota = df_val[df_val.model_name.isin(SOTA)]\n",
    "df_test = df[df.cut == 'test']\n",
    "df_test_sota = df_test[df_test.model_name.isin(SOTA)]\n",
    "\n",
    "dataset_list = ['XSumFaith', 'Polytope', 'FactCC', 'SummEval', 'FRANK', 'Wang20', 'CLIFF', 'Goyal21', 'Cao22']\n",
    "systems = ['DAE', 'QuestEval', 'SummaC-ZS', 'SummaC-Conv', 'QAFactEval']\n",
    "origins = ['cnndm', 'xsum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame(\n",
    "    columns=['system', 'origin', 'count', 'dataset', 'category', 'bl_acc']\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for system in systems:\n",
    "    df[f'{system}_label'] = None\n",
    "\n",
    "for system in systems:\n",
    "    for origin in origins:\n",
    "        for dataset in dataset_list:\n",
    "            for i, model_novelty in enumerate([SOTA, XFORMER, OLD]):\n",
    "                df_val_temp = df_val[(df_val.dataset == dataset) & (df_val.origin == origin) & (df_val.model_name.isin(model_novelty))]\n",
    "                df_test_temp = df_test[(df_test.dataset == dataset) & (df_test.origin == origin) & (df_test.model_name.isin(model_novelty))]\n",
    "\n",
    "                if len(df_val_temp) > 0 and len(df_test_temp) > 0:\n",
    "                    best_thresh, best_f1 = choose_best_threshold(df_val_temp.label.values, df_val_temp[f'{system}_score'].values)\n",
    "\n",
    "                    scores_test = df_test_temp[f'{system}_score'].values\n",
    "                    preds_test = [1 if score > best_thresh else 0 for score in scores_test]\n",
    "                    df.loc[df_test_temp.index, f'{system}_label'] = preds_test\n",
    "                    \n",
    "                    balanced_acc = sklearn.metrics.balanced_accuracy_score(df_test_temp.label.values, preds_test)\n",
    "\n",
    "                    main_df.loc[len(main_df.index)] = [\n",
    "                        system, origin, len(preds_test), dataset, MAPPING[i], balanced_acc\n",
    "                    ]\n",
    "\n",
    "                    results.append({\"system\": system, \"dataset_name\": dataset, 'origin': origin, \n",
    "                    'count': len(scores_test), 'cat': MAPPING[i], \"labels\": df_test_temp.label.values, \n",
    "                    \"preds\": preds_test, \"scores\": scores_test})\n",
    "\n",
    "df = df.reindex(\n",
    "    columns=['dataset', 'origin', 'id', 'doc', 'summary', 'model_name', 'label',\n",
    "       'cut', 'DAE_score', 'DAE_label', 'QuestEval_score', 'QuestEval_label',\n",
    "       'SummaC-ZS_score', 'SummaC-ZS_label', 'SummaC-Conv_score', 'SummaC-Conv_label', \n",
    "       'QAFactEval_score' , 'QAFactEval_label'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dataset-wise comparsion between factuality systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>system</th>\n",
       "      <th>DAE</th>\n",
       "      <th>QuestEval</th>\n",
       "      <th>SummaC-ZS</th>\n",
       "      <th>SummaC-Conv</th>\n",
       "      <th>QAFactEval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>origin</th>\n",
       "      <th>dataset</th>\n",
       "      <th>category</th>\n",
       "      <th>count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">cnndm</th>\n",
       "      <th>CLIFF</th>\n",
       "      <th>SOTA</th>\n",
       "      <th>150</th>\n",
       "      <td>0.730</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">FRANK</th>\n",
       "      <th>OLD</th>\n",
       "      <th>523</th>\n",
       "      <td>0.704</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.692</td>\n",
       "      <td>0.727</td>\n",
       "      <td>0.773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOTA</th>\n",
       "      <th>175</th>\n",
       "      <td>0.699</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XFORMER</th>\n",
       "      <th>175</th>\n",
       "      <td>0.574</td>\n",
       "      <td>0.556</td>\n",
       "      <td>0.631</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FactCC</th>\n",
       "      <th>OLD</th>\n",
       "      <th>503</th>\n",
       "      <td>0.704</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goyal21</th>\n",
       "      <th>OLD</th>\n",
       "      <th>25</th>\n",
       "      <td>0.188</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.354</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Polytope</th>\n",
       "      <th>OLD</th>\n",
       "      <th>450</th>\n",
       "      <td>0.779</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.802</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOTA</th>\n",
       "      <th>34</th>\n",
       "      <td>0.294</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XFORMER</th>\n",
       "      <th>150</th>\n",
       "      <td>0.774</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SummEval</th>\n",
       "      <th>OLD</th>\n",
       "      <th>548</th>\n",
       "      <td>0.661</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SOTA</th>\n",
       "      <th>200</th>\n",
       "      <td>0.452</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XFORMER</th>\n",
       "      <th>50</th>\n",
       "      <td>0.760</td>\n",
       "      <td>0.680</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wang20</th>\n",
       "      <th>OLD</th>\n",
       "      <th>117</th>\n",
       "      <td>0.586</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">xsum</th>\n",
       "      <th>CLIFF</th>\n",
       "      <th>SOTA</th>\n",
       "      <th>150</th>\n",
       "      <td>0.754</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.596</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cao22</th>\n",
       "      <th>SOTA</th>\n",
       "      <th>239</th>\n",
       "      <td>0.723</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Goyal21</th>\n",
       "      <th>SOTA</th>\n",
       "      <th>50</th>\n",
       "      <td>0.644</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wang20</th>\n",
       "      <th>SOTA</th>\n",
       "      <th>119</th>\n",
       "      <td>0.756</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">XSumFaith</th>\n",
       "      <th>OLD</th>\n",
       "      <th>430</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XFORMER</th>\n",
       "      <th>423</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "system                             DAE  QuestEval  SummaC-ZS  SummaC-Conv  \\\n",
       "origin dataset   category count                                             \n",
       "cnndm  CLIFF     SOTA     150    0.730      0.740      0.646        0.649   \n",
       "       FRANK     OLD      523    0.704      0.670      0.692        0.727   \n",
       "                 SOTA     175    0.699      0.626      0.570        0.601   \n",
       "                 XFORMER  175    0.574      0.556      0.631        0.634   \n",
       "       FactCC    OLD      503    0.704      0.655      0.835        0.891   \n",
       "       Goyal21   OLD      25     0.188      0.146      0.375        0.354   \n",
       "       Polytope  OLD      450    0.779      0.687      0.802        0.791   \n",
       "                 SOTA     34     0.294      0.176      0.971        0.735   \n",
       "                 XFORMER  150    0.774      0.733      0.970        0.811   \n",
       "       SummEval  OLD      548    0.661      0.649      0.773        0.801   \n",
       "                 SOTA     200    0.452      0.649      0.622        0.827   \n",
       "                 XFORMER  50     0.760      0.680      0.620        0.580   \n",
       "       Wang20    OLD      117    0.586      0.552      0.655        0.672   \n",
       "xsum   CLIFF     SOTA     150    0.754      0.619      0.596        0.666   \n",
       "       Cao22     SOTA     239    0.723      0.601      0.490        0.668   \n",
       "       Goyal21   SOTA     50     0.644      0.814      0.466        0.552   \n",
       "       Wang20    SOTA     119    0.756      0.560      0.698        0.721   \n",
       "       XSumFaith OLD      430    0.834      0.597      0.533        0.675   \n",
       "                 XFORMER  423    0.855      0.601      0.514        0.646   \n",
       "\n",
       "system                           QAFactEval  \n",
       "origin dataset   category count              \n",
       "cnndm  CLIFF     SOTA     150         0.716  \n",
       "       FRANK     OLD      523         0.773  \n",
       "                 SOTA     175         0.547  \n",
       "                 XFORMER  175         0.646  \n",
       "       FactCC    OLD      503         0.843  \n",
       "       Goyal21   OLD      25          0.271  \n",
       "       Polytope  OLD      450         0.824  \n",
       "                 SOTA     34          0.324  \n",
       "                 XFORMER  150         0.726  \n",
       "       SummEval  OLD      548         0.814  \n",
       "                 SOTA     200         0.652  \n",
       "                 XFORMER  50          0.740  \n",
       "       Wang20    OLD      117         0.754  \n",
       "xsum   CLIFF     SOTA     150         0.626  \n",
       "       Cao22     SOTA     239         0.613  \n",
       "       Goyal21   SOTA     50          0.754  \n",
       "       Wang20    SOTA     119         0.756  \n",
       "       XSumFaith OLD      430         0.605  \n",
       "                 XFORMER  423         0.596  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 8\n",
    "main_df_pivot_bacc = main_df.pivot(index=['origin', 'dataset', 'category', 'count'], columns='system', values='bl_acc')\n",
    "main_df_pivot_bacc = main_df_pivot_bacc.reindex(columns=systems)\n",
    "main_df_pivot_bacc.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AggreFact-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAE</th>\n",
       "      <th>QuestEval</th>\n",
       "      <th>SummaC-ZS</th>\n",
       "      <th>SummaC-Conv</th>\n",
       "      <th>QAFactEval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SOTA</th>\n",
       "      <td>0.594</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XFORMER</th>\n",
       "      <td>0.679</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLD</th>\n",
       "      <td>0.697</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DAE  QuestEval  SummaC-ZS  SummaC-Conv  QAFactEval\n",
       "SOTA     0.594      0.637      0.633        0.703       0.616\n",
       "XFORMER  0.679      0.643      0.765        0.698       0.691\n",
       "OLD      0.697      0.652      0.763        0.790       0.803"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 4\n",
    "scores = []\n",
    "for cat in MAPPING.values():\n",
    "    score = []\n",
    "    for system in systems:\n",
    "        system_df = main_df[(main_df.system == system) & (main_df.category == cat) & (main_df.origin == 'cnndm')]\n",
    "        value = sum(system_df['count'] * system_df['bl_acc']) / sum(system_df['count'])\n",
    "        score.append(round(value, 3))\n",
    "    scores.append(score)\n",
    "\n",
    "weighted_df = pd.DataFrame(\n",
    "    scores,\n",
    "    columns=systems,\n",
    "    index=['SOTA', 'XFORMER', 'OLD']\n",
    ")\n",
    "weighted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AggreFact-XSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAE</th>\n",
       "      <th>QuestEval</th>\n",
       "      <th>SummaC-ZS</th>\n",
       "      <th>SummaC-Conv</th>\n",
       "      <th>QAFactEval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SOTA</th>\n",
       "      <td>0.731</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XFORMER</th>\n",
       "      <td>0.855</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OLD</th>\n",
       "      <td>0.834</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           DAE  QuestEval  SummaC-ZS  SummaC-Conv  QAFactEval\n",
       "SOTA     0.731      0.616      0.561        0.668       0.660\n",
       "XFORMER  0.855      0.601      0.514        0.646       0.596\n",
       "OLD      0.834      0.597      0.533        0.675       0.605"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table 4\n",
    "scores = []\n",
    "for cat in MAPPING.values():\n",
    "    score = []\n",
    "    for system in systems:\n",
    "        system_df = main_df[(main_df.system == system) & (main_df.category == cat) & (main_df.origin == 'xsum')]\n",
    "        value = sum(system_df['count'] * system_df['bl_acc']) / sum(system_df['count'])\n",
    "        score.append(round(value, 3))\n",
    "    scores.append(score)\n",
    "\n",
    "weighted_df = pd.DataFrame(\n",
    "    scores,\n",
    "    columns=systems,\n",
    "    index=['SOTA', 'XFORMER', 'OLD']\n",
    ")\n",
    "weighted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AggreFact-CNN/XSum-SOTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import resample_balanced_acc\n",
    "\n",
    "main_sota_df = pd.DataFrame(\n",
    "    columns=['system', 'origin', 'bl_acc']\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for system in systems:\n",
    "    for origin in origins:\n",
    "            df_val_temp = df_val_sota[(df_val_sota.origin == origin)]\n",
    "            df_test_temp = df_test_sota[(df_test_sota.origin == origin)]\n",
    "\n",
    "            best_thresh, best_f1 = choose_best_threshold(df_val_temp.label.values, df_val_temp[f'{system}_score'].values)\n",
    "\n",
    "            scores_test = df_test_temp[f'{system}_score'].values\n",
    "            preds_test = [1 if score > best_thresh else 0 for score in scores_test]\n",
    "            \n",
    "            f1_score = sklearn.metrics.balanced_accuracy_score(df_test_temp.label.values, preds_test)\n",
    "\n",
    "            main_sota_df.loc[len(main_sota_df.index)] = [\n",
    "                system, origin, f1_score\n",
    "            ]\n",
    "\n",
    "            results.append({\"system\": system, 'origin': origin,  \"labels\": df_test_temp.label.values, \n",
    "            \"preds\": preds_test, \"scores\": scores_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnndm          DAE           - 0.654, 0.036\n",
      "cnndm       QuestEval        - 0.702, 0.031\n",
      "cnndm       SummaC-ZS        - 0.640, 0.032\n",
      "cnndm      SummaC-Conv       - 0.610, 0.032\n",
      "cnndm       QAFactEval       - 0.678, 0.034\n",
      "\n",
      " xsum          DAE           - 0.702, 0.018\n",
      " xsum       QuestEval        - 0.595, 0.021\n",
      " xsum       SummaC-ZS        - 0.564, 0.014\n",
      " xsum      SummaC-Conv       - 0.650, 0.020\n",
      " xsum       QAFactEval       - 0.639, 0.020\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Table 5\n",
    "# standard deviation may differ due to randomness\n",
    "\n",
    "# from https://github.com/tingofurro/summac/\n",
    "P5 = 5 / 2 # Correction due to the fact that we are running 2 tests with the same data\n",
    "P1 = 1 / 2 # Correction due to the fact that we are running 2 tests with the same data\n",
    "\n",
    "for origin in origins:\n",
    "    sampled_batch_preds = {res[\"system\"]: [] for res in results}\n",
    "    \n",
    "    for res in results:\n",
    "        if res['origin'] == origin:\n",
    "    \n",
    "            samples = resample_balanced_acc(res[\"preds\"], res[\"labels\"])\n",
    "            sampled_batch_preds[res[\"system\"]].append(samples)\n",
    "            low5, high5 = np.percentile(samples, P5), np.percentile(samples, 100-P5)\n",
    "            low1, high1 = np.percentile(samples, P1), np.percentile(samples, 100-P1)\n",
    "            bacc = sklearn.metrics.balanced_accuracy_score(res[\"labels\"], res[\"preds\"])\n",
    "\n",
    "            print(res['origin'].center(6), res[\"system\"].center(20), \" - %.3f, %.3f\" % (bacc, bacc-low5))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b59c53c64597fe44953bbb80381bd95288c336271f58402d1e3936b61a22f28"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('AggreFact': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
